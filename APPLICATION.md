# üéØ Application pour le poste de Software Engineer Intern chez Mistral AI

**Candidat:** Malek Gatoufi  
**Projet:** MistralMeter - Production-Grade LLM Evaluation Platform  
**Repository:** https://github.com/malek-gatoufi/MistralMeter
**Date:** Janvier 2026

---

## üì¶ Projet Soumis

### MistralMeter - Plateforme d'√âvaluation LLM

**Technologies utilis√©es:**
- ‚úÖ **Backend:** Python + FastAPI (async, type-safe avec Pydantic)
- ‚úÖ **Frontend:** Nuxt 3 + TypeScript + Tailwind CSS
- ‚úÖ **Containerisation:** Docker/Podman avec docker-compose
- ‚úÖ **API Mistral:** Int√©gration compl√®te avec le SDK officiel

**Scope du projet:**
- √âvaluation de qualit√© des r√©ponses LLM (LLM-as-Judge)
- Mesure de performance (latency, TTFT, throughput)
- Analyse statistique avec variance multi-runs
- Comparaison A/B de mod√®les Mistral
- Dashboard interactif avec streaming SSE
- Gestion de datasets et batch evaluation

---

## ‚ú® Pourquoi ce projet?

### 1. R√©sout un probl√®me r√©el
En production, √©valuer les LLMs est complexe:
- Non-d√©terminisme des r√©ponses
- Trade-offs entre qualit√©, latence et co√ªt
- Biais des juges automatiques

MistralMeter rend ces trade-offs **explicites et mesurables**.

### 2. D√©montre des comp√©tences techniques solides
- Architecture full-stack moderne et scalable
- APIs REST bien con√ßues avec documentation OpenAPI
- Code type-safe (Pydantic + TypeScript)
- Containerisation et d√©ploiement facile
- UI/UX soign√©e avec Tailwind

### 3. Best Practices respect√©es
- ‚úÖ README d√©taill√© avec Quick Start
- ‚úÖ Facile √† tester (docker-compose up)
- ‚úÖ Code structur√© et maintenable
- ‚úÖ Documentation technique compl√®te
- ‚úÖ S√©paration des responsabilit√©s (mod√®le √©valu√© ‚â† juge)

---

## üöÄ Quick Start pour les Reviewers

### Lancement en 2 minutes:

```bash
# 1. Clone
git clone git@github.com:malek-gatoufi/MistralMeter.git
cd mistral-eval-platform

# 2. Ajouter la cl√© API
echo "MISTRAL_API_KEY=your_key_here" > .env

# 3. Lancer tout avec Docker
docker-compose up -d
```

**Services disponibles:**
- Dashboard: http://localhost:3000
- API Docs: http://localhost:8000/docs

### Test rapide sans Docker:

```bash
# Backend seulement
pip install -r requirements.txt
cp .env.example .env  # Ajouter votre MISTRAL_API_KEY
uvicorn app.main:app --reload

# Puis tester dans le navigateur:
# http://localhost:8000/docs
```

---

## üìñ Documentation

Le projet inclut une documentation compl√®te:

### README principal
- Vue d'ensemble du projet
- Justification technique
- Quick Start complet
- R√©f√©rence API
- Architecture
- Future work

### Documentation interne (dans /docs - priv√©)
- `ENGINEERING_DECISIONS.md` - Choix architecturaux
- `FEATURES_SUMMARY.md` - Liste des fonctionnalit√©s
- `FRONTEND_IMPROVEMENTS.md` - Am√©liorations frontend
- `experiments.md` - Notes de d√©veloppement
- `Project.md` - Notes du projet

### Documentation conceptuelle (dans /guides - public)
- 9 documents expliquant les concepts d'√©valuation LLM
- Topics: LLM-as-judge, variance, tokenization, streaming, etc.

---

## üí° Highlights Techniques

### 1. LLM-as-Judge avec S√©paration des Mod√®les
```python
# Le mod√®le √©valu√© ‚â† le mod√®le juge (√©vite le biais)
{
  "model": "mistral-small-latest",      # √âvalu√©
  "judge_model": "mistral-large-latest" # Juge
}
```

### 2. Mesure de Variance Multi-Runs
```python
# Analyse statistique sur 5 runs
{
  "runs": 5,
  "metrics": {
    "quality": {
      "mean": 8.2,
      "std_dev": 0.4,
      "p50": 8.3,
      "p95": 8.7
    }
  }
}
```

### 3. Streaming SSE pour UI R√©active
```python
@app.post("/stream")
async def stream_tokens():
    async for chunk in stream:
        yield f"data: {json.dumps(chunk)}\n\n"
```

### 4. Architecture Async-First
```python
# FastAPI async pour g√©rer les appels IO-bound
async def evaluate_prompt(prompt: str):
    async with mistral_client as client:
        response = await client.chat(...)
```

---

## üéØ Alignment avec l'Offre Mistral

### Comp√©tences demand√©es:

‚úÖ **Full-stack (Python/TypeScript)** ‚Üí FastAPI + Nuxt 3  
‚úÖ **UX de qualit√©** ‚Üí Dashboard Tailwind soign√©  
‚úÖ **Solutions bas√©es sur Chat APIs** ‚Üí Int√©gration compl√®te SDK Mistral  
‚úÖ **Adaptation rapide** ‚Üí Projet complet r√©alis√© en temps limit√©  
‚úÖ **Outils pour d√©veloppeurs** ‚Üí API docs, CLI-friendly, containeris√©

### Types de projets sugg√©r√©s:

**Python Project avec FastAPI** ‚úÖ
- Utilise FastAPI pour l'API backend
- Int√®gre le SDK Mistral
- D√©montre des patterns de production

**Flexible avec TypeScript** ‚úÖ
- Frontend Nuxt 3 + TypeScript
- Composables r√©utilisables
- Type-safety compl√®te

---

## üîÆ √âvolution Potentielle

Si ce projet √©tait adopt√© en interne chez Mistral, il pourrait √©voluer vers:

### Court terme:
- Pipeline d'√©valuation continue sur chaque release
- Syst√®me de d√©tection de r√©gression qualit√©
- Export de r√©sultats pour analyse externe

### Moyen terme:
- Dashboard client pour utilisateurs Enterprise
- A/B testing framework pour optimisation prompts
- Int√©gration avec pipelines RLHF

### Long terme:
- Support multi-providers (benchmarking comp√©titif)
- √âvaluation de fine-tuned models
- M√©triques RAG et agents multi-steps

---

## üìä Statistiques du Projet

```bash
# Code statistics
Backend:  ~800 lignes Python (app/)
Frontend: ~1200 lignes TypeScript/Vue (frontend/)
Docs:     9 documents techniques + README complet
Tests:    [√Ä ajouter selon vos tests]
```

**Temps de d√©veloppement:** ~15-20 heures  
**Complexit√©:** Production-grade, pas over-engineered  
**Testabilit√©:** Docker one-command deployment

---

## üéì Ce que j'ai Appris

### Techniques:
- Patterns d'√©valuation LLM (LLM-as-judge, variance analysis)
- Optimisation de latence et throughput
- Streaming SSE pour UI temps-r√©el
- Architecture async-first en Python

### Engineering:
- Trade-offs architecture (simplicit√© vs features)
- Documentation pour onboarding rapide
- Containerisation pour reproductibilit√©
- API design pour developer experience

### Business:
- Probl√©matiques r√©elles des √©quipes LLM en production
- Importance de la mesure vs l'intuition
- Besoins d'√©valuation pour clients Enterprise

---

## üöÄ Prochaines √âtapes

### Pour le push GitHub:

1. ‚úÖ V√©rifier que `.gitignore` exclut bien:
   - `.env` (secrets)
   - `reports/` (docs internes)
   - `__pycache__/`, `.venv/`

2. ‚úÖ S'assurer que le README est √† jour

3. üì§ Push sur GitHub:
   ```bash
   git init
   git add .
   git commit -m "Initial commit: MistralMeter evaluation platform"
   git remote add origin <votre-repo>
   git push -u origin main
   ```

4. üìß Dans l'email de candidature, inclure:
   - Lien vers le repo GitHub
   - Ce document APPLICATION.md
   - Bref pitch (2-3 phrases)

### Email Template:

```
Objet: Software Engineer Intern - MistralMeter Project

Bonjour,

Je soumets ma candidature pour le poste de Software Engineer Intern chez Mistral AI.

Projet: MistralMeter - Production-Grade LLM Evaluation Platform
GitHub: [VOTRE_LIEN]

MistralMeter est une plateforme d'√©valuation LLM construite avec FastAPI + Nuxt 3, 
d√©montrant des comp√©tences en full-stack development et une compr√©hension des d√©fis 
d'√©valuation LLM en production (variance, LLM-as-judge, metrics collection).

Le projet est enti√®rement containeris√© et d√©marre avec une seule commande: 
`docker-compose up`.

Documentation compl√®te dans le README.

Cordialement,
Malek Gatoufi
```

---

## ‚ú® Pourquoi Mistral?

### Vision technique
Mistral combine excellence technique (Mixtral MoE, performance SOTA) et pragmatisme 
(mod√®les optimis√©s pour production). C'est exactement le type d'environnement o√π je 
veux apprendre.

### Impact europ√©en
Contribuer √† un champion europ√©en de l'IA qui prouve que l'Europe peut rivaliser 
techniquement avec les g√©ants US.

### Open Science
L'engagement de Mistral vers l'open source (Mistral 7B, Mixtral) aligne avec mes 
valeurs sur la d√©mocratisation de l'IA.

### Croissance rapide
Environnement startup o√π l'impact individuel est √©lev√© et l'apprentissage acc√©l√©r√©.

---

**üéØ Ready to push and apply!**

---

*Document cr√©√© le 17 janvier 2026*
